# QSP Compliance Checker: Code Comparison
## Custom MCP Implementation vs. Kalibr SDK Approach

This document demonstrates the difference in code complexity, implementation time, and maintenance between our current custom MCP WebSocket implementation and what the same functionality would require using the Kalibr SDK.

---

## üîÑ Current Custom MCP Implementation

### Required Files & Code Volume
- **Custom WebSocket Server**: ~700 lines in `server.py` (lines 668-1370)
- **MCP Protocol Handling**: Manual JSON-RPC implementation
- **Tool Definitions**: Hand-coded schema definitions
- **Base64 File Processing**: Custom implementation
- **Error Handling**: Manual implementation
- **Multi-Model Support**: Separate endpoint configurations

### Current Implementation in `server.py` (700+ lines)

```python
# Store active WebSocket connections for MCP
active_mcp_connections: Dict[str, WebSocket] = {}

# MCP WebSocket endpoint
@app.websocket("/mcp")
async def mcp_websocket_endpoint(websocket: WebSocket):
    """WebSocket endpoint for MCP protocol communication with Claude/ChatGPT"""
    await websocket.accept()
    connection_id = str(uuid.uuid4())
    active_mcp_connections[connection_id] = websocket
    
    logger.info(f"New MCP connection: {connection_id}")
    
    try:
        while True:
            # Receive message from client (Claude/ChatGPT)
            data = await websocket.receive_text()
            message = json.loads(data)
            
            logger.info(f"Received MCP message: {message.get('method', 'unknown')}")
            
            # Handle MCP protocol messages
            response = await handle_mcp_protocol_message(message)
            
            # Send response back
            await websocket.send_text(json.dumps(response))
            
    except Exception as e:
        logger.error(f"MCP WebSocket error: {e}")
    finally:
        if connection_id in active_mcp_connections:
            del active_mcp_connections[connection_id]
        logger.info(f"MCP connection closed: {connection_id}")

async def handle_mcp_protocol_message(message: Dict[str, Any]) -> Dict[str, Any]:
    """Handle incoming MCP protocol messages"""
    
    method = message.get("method")
    params = message.get("params", {})
    message_id = message.get("id")
    
    try:
        if method == "initialize":
            return {
                "jsonrpc": "2.0",
                "id": message_id,
                "result": {
                    "protocolVersion": "2024-11-05",
                    "capabilities": {
                        "tools": {},
                        "prompts": {},
                        "resources": {}
                    },
                    "serverInfo": {
                        "name": "qsp-compliance-checker",
                        "version": "1.0.0"
                    }
                }
            }
        
        elif method == "tools/list":
            tools = [
                {
                    "name": "upload_qsp_document",
                    "description": "Upload a QSP document for compliance analysis",
                    "inputSchema": {
                        "type": "object",
                        "properties": {
                            "filename": {"type": "string"},
                            "content": {"type": "string", "description": "Base64 encoded file content"},
                            "file_type": {"type": "string", "enum": ["txt", "docx"]}
                        },
                        "required": ["filename", "content", "file_type"]
                    }
                },
                # ... 9 more tool definitions (200+ lines of JSON schemas)
            ]
            
            return {
                "jsonrpc": "2.0",
                "id": message_id,
                "result": {"tools": tools}
            }
        
        elif method == "tools/call":
            tool_name = params.get("name")
            arguments = params.get("arguments", {})
            
            # Convert base64 content for file uploads
            if tool_name in ["upload_qsp_document", "upload_iso_summary"] and "content" in arguments:
                arguments["base64_content"] = arguments.pop("content", "")
            
            # Call the appropriate tool
            result_text = await call_mcp_tool(tool_name, arguments)
            
            return {
                "jsonrpc": "2.0", 
                "id": message_id,
                "result": {
                    "content": [{"type": "text", "text": result_text}]
                }
            }
        
        else:
            return {
                "jsonrpc": "2.0",
                "id": message_id,
                "error": {
                    "code": -32601,
                    "message": f"Method not found: {method}"
                }
            }
    
    except Exception as e:
        logger.error(f"Error handling MCP message: {e}")
        return {
            "jsonrpc": "2.0",
            "id": message_id, 
            "error": {
                "code": -32603,
                "message": f"Internal error: {str(e)}"
            }
        }

# 10 separate MCP tool implementations (400+ lines)
async def mcp_upload_qsp_document(args: dict) -> str:
    """MCP version of document upload"""
    filename = args["filename"]
    file_type = args["file_type"]
    base64_content = args["base64_content"]
    
    try:
        # Decode base64 content
        content = base64.b64decode(base64_content)
        
        # Extract text
        if file_type == "docx":
            doc = Document(io.BytesIO(content))
            text_content = '\n'.join([p.text for p in doc.paragraphs if p.text.strip()])
        else:  # txt
            text_content = content.decode('utf-8')
        
        # ... 50+ lines of document processing logic
        
        return f"‚úÖ **QSP Document Uploaded Successfully**..."
        
    except Exception as e:
        return f"‚ùå Upload failed: {str(e)}"

# ... 9 more similar functions with 30-50 lines each

@api_router.get("/mcp/setup")
async def get_mcp_setup_instructions():
    """Get MCP setup instructions for Claude Desktop and ChatGPT"""
    domain = os.environ.get('DOMAIN', 'qsp-compliance.preview.emergentagent.com')
    
    return {
        "title": "QSP Compliance Checker - MCP Setup",
        "status": "ready",
        "websocket_endpoint": f"wss://{domain}/mcp",
        # ... 50+ lines of configuration JSON
    }
```

**Issues with Current Approach:**
- ‚ùå **700+ lines of boilerplate MCP code**
- ‚ùå **Manual JSON-RPC protocol implementation**
- ‚ùå **Duplicate function implementations** (REST API + MCP versions)
- ‚ùå **Complex WebSocket connection management**
- ‚ùå **Manual schema generation for each tool**
- ‚ùå **No built-in error handling patterns**
- ‚ùå **Separate configurations needed for each AI model**
- ‚ùå **Manual base64 encoding/decoding**
- ‚ùå **Complex deployment setup instructions**

---

## üöÄ Kalibr SDK Implementation

### Required Files & Code Volume
- **Single Application File**: ~150 lines total
- **Automatic Protocol Handling**: Built-in MCP/GPT/Gemini/Copilot support
- **Automatic Schema Generation**: From function signatures
- **Built-in File Handling**: Native support for uploads
- **Auto Error Handling**: Framework-provided
- **Single Deployment**: Works with all AI models

### Kalibr Implementation (150 lines vs 700+ lines)

```python
# qsp_compliance_kalibr.py
from kalibr import KalibrApp
from kalibr.types import FileUpload, Session
from kalibr.auth_helpers import kalibr_auth, KalibrAuth
from kalibr.analytics import kalibr_analytics
from motor.motor_asyncio import AsyncIOMotorClient
from docx import Document
import os
import io
from datetime import datetime, timezone
from pydantic import BaseModel
from typing import List, Dict, Any
from emergentintegrations.llm.chat import LlmChat, UserMessage

# Initialize MongoDB (same as current)
mongo_url = os.environ['MONGO_URL']
client = AsyncIOMotorClient(mongo_url)
db = client[os.environ['DB_NAME']]

# Initialize Kalibr App with analytics
@kalibr_analytics(storage="mongodb", auto_track=True)
class QSPComplianceApp(KalibrApp):
    def __init__(self):
        super().__init__(
            title="QSP Compliance Checker",
            description="AI-powered ISO 13485:2024 compliance analysis for medical device QSPs"
        )

app = QSPComplianceApp()

# Tool 1: Upload QSP Document
@app.file_handler(
    name="upload_qsp_document",
    description="Upload and analyze QSP documents (.docx or .txt) for ISO 13485 compliance",
    allowed_extensions=["txt", "docx"]
)
async def upload_qsp_document(file: FileUpload) -> dict:
    """Upload a QSP document for compliance analysis"""
    
    # Extract text content
    if file.filename.endswith('.docx'):
        doc = Document(io.BytesIO(file.content))
        text_content = '\n'.join([p.text for p in doc.paragraphs if p.text.strip()])
    else:
        text_content = file.content.decode('utf-8')
    
    # Parse sections (reuse existing logic)
    sections = await parse_document_sections(text_content, file.filename)
    
    # Create and store document
    qsp_doc = {
        "id": str(uuid.uuid4()),
        "filename": file.filename,
        "content": text_content,
        "sections": sections,
        "upload_date": datetime.now(timezone.utc).isoformat(),
        "processed": True
    }
    
    await db.qsp_documents.insert_one(qsp_doc)
    
    return {
        "success": True,
        "message": f"Document '{file.filename}' uploaded successfully",
        "document_id": qsp_doc["id"],
        "sections_count": len(sections),
        "content_length": len(text_content)
    }

# Tool 2: Upload ISO Summary
@app.file_handler(
    name="upload_iso_summary",
    description="Upload ISO 13485:2024 Summary of Changes for compliance benchmarking", 
    allowed_extensions=["txt", "docx", "pdf"]
)
async def upload_iso_summary(file: FileUpload) -> dict:
    """Upload ISO 13485:2024 Summary of Changes"""
    
    # Extract and parse ISO content (reuse existing logic)
    if file.filename.endswith('.docx'):
        doc = Document(io.BytesIO(file.content))
        text_content = '\n'.join([p.text for p in doc.paragraphs if p.text.strip()])
    else:
        text_content = file.content.decode('utf-8')
    
    # Parse clauses (reuse existing logic)
    new_clauses, modified_clauses = await parse_iso_clauses(text_content)
    
    iso_summary = {
        "id": str(uuid.uuid4()),
        "framework": "ISO_13485",
        "version": "2024_summary", 
        "content": text_content,
        "new_clauses": new_clauses,
        "modified_clauses": modified_clauses,
        "upload_date": datetime.now(timezone.utc).isoformat()
    }
    
    await db.iso_summaries.insert_one(iso_summary)
    
    return {
        "success": True,
        "message": "ISO summary uploaded successfully",
        "new_clauses": len(new_clauses),
        "modified_clauses": len(modified_clauses)
    }

# Tool 3: List Documents
@app.action(
    name="list_documents",
    description="Get all uploaded QSP documents with their processing status"
)
async def list_documents(format: str = "summary") -> dict:
    """List all QSP documents"""
    
    docs = await db.qsp_documents.find({}, {"_id": 0}).to_list(length=None)
    
    if format == "detailed":
        return {"documents": docs, "count": len(docs)}
    
    summary = [
        {
            "filename": doc["filename"],
            "sections": len(doc.get("sections", {})),
            "upload_date": doc["upload_date"],
            "processed": doc.get("processed", False)
        }
        for doc in docs
    ]
    
    return {"documents": summary, "count": len(docs)}

# Tool 4: Run AI Clause Mapping
@app.action(
    name="run_clause_mapping", 
    description="Execute AI-powered mapping between QSP sections and ISO 13485 clauses"
)
async def run_clause_mapping() -> dict:
    """Run AI-powered clause mapping analysis"""
    
    # Get documents
    qsp_docs = await db.qsp_documents.find({}, {"_id": 0}).to_list(length=None)
    if not qsp_docs:
        raise ValueError("No QSP documents found. Upload documents first.")
    
    # Clear existing mappings
    await db.clause_mappings.delete_many({})
    
    # Run AI analysis (reuse existing logic)
    total_mappings = 0
    for doc in qsp_docs:
        mappings = await analyze_clause_mapping_with_ai(doc)
        total_mappings += len(mappings)
    
    return {
        "success": True,
        "documents_processed": len(qsp_docs),
        "mappings_generated": total_mappings,
        "message": "AI clause mapping completed successfully"
    }

# Tool 5: Run Compliance Analysis
@app.action(
    name="run_compliance_analysis",
    description="Analyze compliance gaps between current QSPs and ISO 13485:2024 changes"
)
async def run_compliance_analysis() -> dict:
    """Run comprehensive compliance gap analysis"""
    
    # Get required data
    iso_summary = await db.iso_summaries.find_one({}, {"_id": 0})
    if not iso_summary:
        raise ValueError("No ISO summary found. Upload ISO 13485:2024 Summary first.")
    
    mappings = await db.clause_mappings.find({}, {"_id": 0}).to_list(length=None)
    if not mappings:
        raise ValueError("No clause mappings found. Run clause mapping first.")
    
    # Run gap analysis (reuse existing logic) 
    gaps = await analyze_compliance_gaps(iso_summary, mappings)
    overall_score = calculate_compliance_score(gaps, mappings)
    
    # Store results
    analysis = {
        "id": str(uuid.uuid4()),
        "overall_score": overall_score,
        "gaps_count": len(gaps),
        "high_priority_gaps": len([g for g in gaps if g["severity"] == "high"]),
        "analysis_date": datetime.now(timezone.utc).isoformat()
    }
    
    await db.compliance_analyses.insert_one(analysis)
    
    return {
        "success": True,
        "overall_score": overall_score,
        "gaps_found": len(gaps),
        "high_priority": len([g for g in gaps if g["severity"] == "high"]),
        "message": "Compliance analysis completed successfully"
    }

# Tool 6: Get Compliance Status
@app.action(
    name="get_compliance_status",
    description="Get current compliance overview with scores and key metrics"
)
async def get_compliance_status() -> dict:
    """Get current compliance status and metrics"""
    
    # Get latest data
    analysis = await db.compliance_analyses.find_one({}, {"_id": 0}, sort=[("analysis_date", -1)])
    total_docs = await db.qsp_documents.count_documents({})
    total_mappings = await db.clause_mappings.count_documents({})
    
    return {
        "compliance_score": analysis["overall_score"] if analysis else 0,
        "total_documents": total_docs,
        "total_mappings": total_mappings,
        "gaps_count": analysis["gaps_count"] if analysis else 0,
        "status": "Ready" if analysis else "Pending Analysis",
        "last_analysis": analysis["analysis_date"] if analysis else None
    }

# Helper functions (reuse existing business logic)
async def parse_document_sections(content: str, filename: str) -> Dict[str, str]:
    # Reuse existing implementation from server.py lines 140-186
    pass

async def parse_iso_clauses(content: str) -> tuple:
    # Reuse existing implementation from server.py lines 332-350
    pass

async def analyze_clause_mapping_with_ai(doc: dict) -> List[dict]:
    # Reuse existing implementation from server.py lines 188-250
    pass

async def analyze_compliance_gaps(iso_summary: dict, mappings: List[dict]) -> List[dict]:
    # Reuse existing implementation from server.py lines 464-546
    pass

async def calculate_compliance_score(gaps: List[dict], mappings: List[dict]) -> float:
    # Reuse existing calculation logic
    pass

# Authentication (optional)
# @app.action("register_user", "Register a new user account")
# @kalibr_auth(secret_key=os.environ["SECRET_KEY"])
# async def register_user(username: str, email: str, password: str):
#     # Authentication implementation if needed
#     pass

if __name__ == "__main__":
    # Development server
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)
```

**Deployment Commands:**
```bash
# Local development
kalibr serve qsp_compliance_kalibr.py

# Deploy to production (all AI models automatically supported)
kalibr deploy qsp_compliance_kalibr.py --platform fly --name qsp-compliance

# Or deploy to AWS Lambda
kalibr deploy qsp_compliance_kalibr.py --platform aws --region us-east-1
```

**Kalibr Advantages:**
- ‚úÖ **150 lines vs 700+ lines** (78% code reduction)
- ‚úÖ **Automatic multi-model support** (GPT, Claude, Gemini, Copilot)
- ‚úÖ **Auto-generated schemas** from function signatures
- ‚úÖ **Built-in file upload handling** with type validation
- ‚úÖ **Automatic error handling and responses**
- ‚úÖ **Single deployment** for all AI models
- ‚úÖ **Built-in analytics and monitoring**
- ‚úÖ **No manual WebSocket management**
- ‚úÖ **No duplicate function implementations**
- ‚úÖ **Production-ready authentication** (if needed)

---

## üìä Comparison Summary

| Feature | Custom MCP Implementation | Kalibr SDK Implementation |
|---------|---------------------------|---------------------------|
| **Lines of Code** | ~700+ lines | ~150 lines |
| **Code Reduction** | - | **78% less code** |
| **AI Model Support** | Manual configuration per model | **Automatic (GPT, Claude, Gemini, Copilot)** |
| **Schema Generation** | Hand-coded JSON schemas | **Auto-generated from functions** |
| **File Upload Handling** | Manual base64 encoding/decoding | **Built-in with type validation** |
| **Error Handling** | Manual try/catch blocks | **Framework-provided patterns** |
| **WebSocket Management** | Custom connection handling | **Abstracted away** |
| **Deployment** | Complex multi-step setup | **Single command deployment** |
| **Authentication** | Not implemented | **Built-in JWT + user management** |
| **Analytics** | Not implemented | **Automatic request tracking** |
| **Maintenance** | High (protocol updates, etc.) | **Low (framework handles updates)** |
| **Development Time** | 2-3 days | **2-3 hours** |
| **Testing Complexity** | Manual WebSocket testing | **Standard HTTP testing** |
| **Documentation Needed** | Extensive setup guides | **Auto-generated API docs** |

---

## üéØ Key Benefits of Kalibr SDK

### 1. **Dramatic Code Reduction** 
- **78% less code** to maintain
- **Single source of truth** for business logic
- **No duplicate implementations** for different AI models

### 2. **Built-in Multi-Model Support**
- Works with **GPT Actions**, **Claude MCP**, **Gemini Extensions**, **Microsoft Copilot**
- **No separate configurations** needed
- **Future-proof** as new AI models are added

### 3. **Production Features Out-of-the-Box**
- **Authentication & authorization** systems
- **Request analytics & monitoring** 
- **Rate limiting & error handling**
- **Session management** for stateful interactions

### 4. **Developer Experience**
- **Type-safe** function definitions
- **Auto-generated documentation**
- **Built-in testing utilities**
- **Hot reload** for development

### 5. **Deployment Simplicity**
- **One command deployment** to multiple cloud platforms
- **Automatic scaling** configuration
- **Built-in health checks** and monitoring

---

## üí° Migration Strategy

If you wanted to migrate from our current custom MCP implementation to Kalibr SDK:

### Phase 1: Core Functions (1-2 hours)
1. Install Kalibr SDK: `pip install kalibr`
2. Create `qsp_compliance_kalibr.py` with 6 core actions
3. Reuse existing business logic functions
4. Test locally: `kalibr serve qsp_compliance_kalibr.py`

### Phase 2: Deploy & Test (30 minutes)  
1. Deploy: `kalibr deploy qsp_compliance_kalibr.py --platform fly`
2. Test with Claude Desktop using auto-generated MCP endpoint
3. Test with ChatGPT using auto-generated OpenAPI schema

### Phase 3: Cleanup (30 minutes)
1. Remove 700+ lines of custom MCP code from `server.py`
2. Keep existing REST API endpoints for React frontend
3. Update documentation with simplified setup

**Total Migration Time: ~3 hours vs weeks of custom development**

---

## ü§î Should We Use Kalibr SDK?

**For Your QSP Compliance Checker:**

**‚úÖ YES, if you want:**
- Minimal maintenance overhead
- Support for all major AI models
- Rapid feature development
- Production-ready authentication/analytics
- Future-proof multi-model integration

**‚ùå Maybe not, if you want:**
- Complete control over WebSocket protocol implementation
- Custom MCP protocol extensions
- Learning experience building MCP from scratch

**Recommendation:** Given that your goal is building a production compliance tool (not a WebSocket learning project), **Kalibr SDK would save you ~90% of the MCP-related development and maintenance effort** while providing broader AI model compatibility and professional features out-of-the-box.